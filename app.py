import base64
import io
import json
import os
import tempfile
from datetime import datetime

import requests as http_requests
import streamlit as st
from PIL import Image

# Bridge st.secrets â†’ os.environ BEFORE importing project modules
# so that config.py (which uses os.getenv) picks up Streamlit Cloud secrets.
_SECRET_KEYS = [
    "TEXT_PROVIDER", "IMAGE_PROVIDER",
    "CLAUDE_API_KEY", "GEMINI_API_KEY", "OPENAI_API_KEY",
    "TELEGRAM_BOT_TOKEN", "TELEGRAM_CHANNEL_ID", "GITHUB_TOKEN",
    "FACE_SWAP_PROVIDER", "REPLICATE_API_KEY",
]
try:
    for _k in _SECRET_KEYS:
        if _k in st.secrets and not os.environ.get(_k):
            os.environ[_k] = str(st.secrets[_k])
except Exception:
    pass

from generate_text import generate_post, DEFAULT_SYSTEM_PROMPT, DEFAULT_IMAGE_PROMPT_TEMPLATE
from generate_image import generate_image
from face_swap import apply_face_swap, load_expert_face_b64
from post_telegram import send_post

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
IDEAS_FILE = os.path.join(BASE_DIR, "ideas.json")
HISTORY_FILE = os.path.join(BASE_DIR, "history.json")
PROMPTS_FILE = os.path.join(BASE_DIR, "prompts.json")
ENV_FILE = os.path.join(BASE_DIR, ".env")

GITHUB_REPO = "alexandermalevich85-commits/telegram-autoposter"
PROVIDER_CFG_PATH = "provider.cfg"
PENDING_POST_PATH = "pending_post.json"
EXPERT_FACE_PATH = "expert_face.json"

# â”€â”€ GitHub API helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _get_github_token() -> str:
    """Get GITHUB_TOKEN from st.secrets (Streamlit Cloud) or env."""
    try:
        if "GITHUB_TOKEN" in st.secrets:
            return str(st.secrets["GITHUB_TOKEN"])
    except Exception:
        pass
    return os.getenv("GITHUB_TOKEN", "")


def _github_headers() -> dict | None:
    """Build GitHub API headers. Returns None if no token."""
    token = _get_github_token()
    if not token:
        return None
    return {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json",
    }


def read_github_file(path: str) -> tuple[str | None, str | None]:
    """Read a file from GitHub repo via Contents API.

    For files > 1 MB the Contents API does not return inline content,
    so we fall back to the raw download URL.

    Returns (content_string, sha) or (None, None) on failure.
    """
    headers = _github_headers()
    if not headers:
        return None, None
    api_url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path}"
    try:
        resp = http_requests.get(api_url, headers=headers, timeout=10)
        if resp.status_code == 200:
            data = resp.json()
            sha = data["sha"]

            # Normal case: file < 1 MB â€” content is base64-encoded inline
            if data.get("content"):
                content = base64.b64decode(data["content"]).decode("utf-8")
                return content, sha

            # Large file (> 1 MB): use download_url for raw content
            download_url = data.get("download_url")
            if download_url:
                raw_resp = http_requests.get(download_url, headers=headers, timeout=30)
                if raw_resp.status_code == 200:
                    return raw_resp.text, sha
    except Exception:
        pass
    return None, None


def write_github_file(
    path: str,
    content: str,
    sha: str | None,
    message: str,
) -> tuple[bool, str]:
    """Write a file to GitHub repo via Contents API.

    Returns (True, "") on success, (False, error_message) on failure.
    """
    headers = _github_headers()
    if not headers:
        return False, "GITHUB_TOKEN Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½"

    api_url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path}"
    encoded = base64.b64encode(content.encode("utf-8")).decode()
    payload = {"message": message, "content": encoded}
    if sha:
        payload["sha"] = sha

    try:
        resp = http_requests.put(api_url, headers=headers, json=payload, timeout=30)
        if resp.status_code in (200, 201):
            return True, ""
        msg = resp.json().get("message", resp.text) if resp.text else f"HTTP {resp.status_code}"
        return False, f"HTTP {resp.status_code}: {msg}"
    except Exception as e:
        return False, str(e)


def update_github_provider_cfg(
    text_provider: str,
    image_provider: str,
    autopublish_enabled: bool | None = None,
    face_swap_provider: str | None = None,
) -> tuple[bool, str]:
    """Update provider.cfg in GitHub repo.

    Returns (True, "") on success, (False, error_message) on failure.
    """
    # Read current file to get SHA and current values
    content, sha = read_github_file(PROVIDER_CFG_PATH)
    current = {}
    if content:
        for line in content.strip().split("\n"):
            if "=" in line:
                k, _, v = line.partition("=")
                current[k.strip()] = v.strip()

    if autopublish_enabled is None:
        autopublish_enabled = current.get("AUTOPUBLISH_ENABLED", "true").lower() != "false"

    if face_swap_provider is None:
        face_swap_provider = current.get("FACE_SWAP_PROVIDER", "")

    enabled_str = "true" if autopublish_enabled else "false"
    new_content = (
        f"TEXT_PROVIDER={text_provider}\n"
        f"IMAGE_PROVIDER={image_provider}\n"
        f"AUTOPUBLISH_ENABLED={enabled_str}\n"
        f"FACE_SWAP_PROVIDER={face_swap_provider}\n"
    )

    return write_github_file(
        PROVIDER_CFG_PATH,
        new_content,
        sha,
        f"Update config: text={text_provider}, image={image_provider}, "
        f"autopublish={enabled_str}, face_swap={face_swap_provider}",
    )


def read_provider_cfg_from_github() -> dict:
    """Read provider.cfg from GitHub and parse it. Returns dict of values."""
    content, _ = read_github_file(PROVIDER_CFG_PATH)
    result = {}
    if content:
        for line in content.strip().split("\n"):
            if "=" in line:
                key, _, val = line.partition("=")
                result[key.strip()] = val.strip()
    return result


# â”€â”€ Local helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def load_json(path: str, default=None):
    if not os.path.exists(path):
        return default if default is not None else []
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def save_json(path: str, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_prompts() -> dict:
    defaults = {
        "system_prompt": DEFAULT_SYSTEM_PROMPT,
        "image_prompt_template": DEFAULT_IMAGE_PROMPT_TEMPLATE,
    }
    saved = load_json(PROMPTS_FILE, {})
    return {**defaults, **saved}


def save_env(values: dict):
    lines = []
    for key, val in values.items():
        lines.append(f"{key}={val}")
    with open(ENV_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(lines) + "\n")


def load_env_values() -> dict:
    values = {}
    if os.path.exists(ENV_FILE):
        with open(ENV_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, _, val = line.partition("=")
                    values[key.strip()] = val.strip()
    return values


def get_expert_face_b64() -> str | None:
    """Get expert face base64: try local file first, then GitHub."""
    # 1. Try local file
    local_b64 = load_expert_face_b64()
    if local_b64:
        return local_b64
    # 2. Try GitHub
    try:
        content, _ = read_github_file(EXPERT_FACE_PATH)
        if content:
            data = json.loads(content)
            b64 = data.get("image_base64")
            if b64:
                # Cache locally for future calls
                local_path = os.path.join(BASE_DIR, "expert_face.json")
                with open(local_path, "w", encoding="utf-8") as f:
                    f.write(content)
                return b64
    except Exception:
        pass
    return None


def image_to_base64(image_path: str) -> str:
    """Compress image to JPEG q85 and return base64 string."""
    img = Image.open(image_path)
    buf = io.BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=85)
    return base64.b64encode(buf.getvalue()).decode("ascii")


def base64_to_bytes(b64_string: str) -> bytes:
    """Decode base64 string to raw bytes."""
    return base64.b64decode(b64_string)


def base64_to_tempfile(b64_string: str) -> str:
    """Decode base64 to a temporary JPEG file, return path."""
    data = base64.b64decode(b64_string)
    fd, path = tempfile.mkstemp(suffix=".jpg", prefix="autoposter_")
    os.close(fd)
    with open(path, "wb") as f:
        f.write(data)
    return path


# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾ÑÑ‚ĞµÑ€ Telegram",
    page_icon="ğŸ“±",
    layout="wide",
)

st.title("ğŸ“± ĞĞ²Ñ‚Ğ¾Ğ¿Ğ¾ÑÑ‚ĞµÑ€ Ğ´Ğ»Ñ Telegram")

# Show flash messages saved before st.rerun()
if st.session_state.pop("_flash_success", None):
    st.success(st.session_state.pop("_flash_msg", "Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!"))

# â”€â”€ Sidebar â€” Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.header("âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸")

    env = load_env_values()

    text_prov = st.selectbox(
        "ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ Ñ‚ĞµĞºÑÑ‚Ğ°",
        ["claude", "gemini", "openai"],
        index=["claude", "gemini", "openai"].index(env.get("TEXT_PROVIDER", "claude"))
        if env.get("TEXT_PROVIDER", "claude") in ["claude", "gemini", "openai"]
        else 0,
    )
    image_prov = st.selectbox(
        "ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ¾Ğº",
        ["gemini", "openai"],
        index=["gemini", "openai"].index(env.get("IMAGE_PROVIDER", "gemini"))
        if env.get("IMAGE_PROVIDER", "gemini") in ["gemini", "openai"]
        else 0,
    )

    st.divider()
    st.subheader("ğŸ”‘ API-ĞºĞ»ÑÑ‡Ğ¸")

    claude_key = st.text_input("Claude API Key", value=env.get("CLAUDE_API_KEY", ""), type="password")
    gemini_key = st.text_input("Gemini API Key", value=env.get("GEMINI_API_KEY", ""), type="password")
    openai_key = st.text_input("OpenAI API Key", value=env.get("OPENAI_API_KEY", ""), type="password")

    st.divider()
    st.subheader("ğŸ“¨ Telegram")

    tg_token = st.text_input("Bot Token", value=env.get("TELEGRAM_BOT_TOKEN", ""), type="password")
    tg_channel = st.text_input("Channel ID", value=env.get("TELEGRAM_CHANNEL_ID", ""))

    st.divider()
    st.subheader("ğŸ­ Face Swap")
    st.caption("Ğ—Ğ°Ğ¼ĞµĞ½Ğ° Ğ»Ğ¸Ñ†Ğ° Ğ½Ğ° Ñ„Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°")

    face_swap_options = ["", "replicate", "gemini", "openai"]
    face_swap_labels = ["Ğ’Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾", "Replicate (Ğ»ÑƒÑ‡ÑˆĞµĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)", "Gemini (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾)", "OpenAI gpt-image-1"]
    current_fs = env.get("FACE_SWAP_PROVIDER", "")
    fs_index = face_swap_options.index(current_fs) if current_fs in face_swap_options else 0
    face_swap_prov = st.selectbox(
        "ĞœĞµÑ‚Ğ¾Ğ´ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ Ğ»Ğ¸Ñ†Ğ°",
        face_swap_options,
        index=fs_index,
        format_func=lambda x: face_swap_labels[face_swap_options.index(x)],
    )

    replicate_key = ""
    if face_swap_prov == "replicate":
        replicate_key = st.text_input(
            "Replicate API Key",
            value=env.get("REPLICATE_API_KEY", ""),
            type="password",
        )

    # Expert face upload
    st.caption("Ğ¤Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° (Ğ´Ğ»Ñ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ Ğ»Ğ¸Ñ†Ğ°)")
    expert_face_file = st.file_uploader(
        "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ„Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°",
        type=["jpg", "jpeg", "png"],
        key="expert_face_upload",
    )

    # Show current expert face status
    expert_b64 = get_expert_face_b64()
    if expert_b64:
        st.success("Ğ¤Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ âœ…")
        if st.checkbox("ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ„Ğ¾Ñ‚Ğ¾", key="show_expert_face"):
            st.image(base64.b64decode(expert_b64), width=150)
    else:
        st.info("Ğ¤Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾")

    if expert_face_file is not None:
        # Save expert face locally and to GitHub
        img = Image.open(expert_face_file)
        buf = io.BytesIO()
        img.convert("RGB").save(buf, format="JPEG", quality=90)
        face_b64 = base64.b64encode(buf.getvalue()).decode("ascii")

        face_json = json.dumps({"image_base64": face_b64}, ensure_ascii=False)

        # Save locally
        local_face_path = os.path.join(BASE_DIR, "expert_face.json")
        with open(local_face_path, "w", encoding="utf-8") as f:
            f.write(face_json)

        # Save to GitHub
        if _get_github_token():
            _, face_sha = read_github_file(EXPERT_FACE_PATH)
            ok, err = write_github_file(
                EXPERT_FACE_PATH, face_json, face_sha,
                "Upload expert face photo [streamlit]",
            )
            if ok:
                st.success("Ğ¤Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ + GitHub) âœ…")
            else:
                st.warning(f"Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾, Ğ½Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° GitHub: {err}")
        else:
            st.success("Ğ¤Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ âœ…")

    if st.button("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸", use_container_width=True):
        env_data = {
            "TEXT_PROVIDER": text_prov,
            "IMAGE_PROVIDER": image_prov,
            "CLAUDE_API_KEY": claude_key,
            "GEMINI_API_KEY": gemini_key,
            "OPENAI_API_KEY": openai_key,
            "TELEGRAM_BOT_TOKEN": tg_token,
            "TELEGRAM_CHANNEL_ID": tg_channel,
            "FACE_SWAP_PROVIDER": face_swap_prov,
        }
        if replicate_key:
            env_data["REPLICATE_API_KEY"] = replicate_key
        save_env(env_data)
        st.success("ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² .env!")

        # Sync providers to GitHub for scheduled runs
        if _get_github_token():
            try:
                ok, err = update_github_provider_cfg(
                    text_prov, image_prov,
                    face_swap_provider=face_swap_prov,
                )
                if ok:
                    st.success("ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ñ GitHub âœ…")
                else:
                    st.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ provider.cfg Ğ½Ğ° GitHub: {err}")
            except Exception as e:
                st.warning(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ GitHub: {e}")
        else:
            st.info("ğŸ’¡ Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ GITHUB_TOKEN Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾-ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² Ñ GitHub Actions")

# â”€â”€ Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

tab_prompts, tab_ideas, tab_create, tab_auto, tab_history = st.tabs(
    ["âœï¸ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹", "ğŸ“‹ Ğ˜Ğ´ĞµĞ¸", "ğŸš€ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ÑÑ‚", "â° ĞĞ²Ñ‚Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ", "ğŸ“Š Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ"]
)

# â”€â”€ Tab: Prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_prompts:
    st.header("âœï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²")

    prompts = load_prompts()

    st.subheader("Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑÑ‚Ğ°")
    st.caption("Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ AI Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¿Ğ¾ÑÑ‚Ğ°")
    new_system = st.text_area(
        "Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚",
        value=prompts["system_prompt"],
        height=350,
        label_visibility="collapsed",
    )

    st.subheader("Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ´Ğ»Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸")
    st.caption("Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ĞºĞ°Ğº fallback, ĞµÑĞ»Ğ¸ AI Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ {idea} Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ñ‚ĞµĞ¼Ñ‹.")
    new_image_tpl = st.text_area(
        "ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸",
        value=prompts["image_prompt_template"],
        height=100,
        label_visibility="collapsed",
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹", use_container_width=True):
            save_json(PROMPTS_FILE, {
                "system_prompt": new_system,
                "image_prompt_template": new_image_tpl,
            })
            st.success("ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹!")
    with col2:
        if st.button("ğŸ”„ Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ", use_container_width=True):
            if os.path.exists(PROMPTS_FILE):
                os.remove(PROMPTS_FILE)
            st.success("ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½Ñ‹!")
            st.rerun()

# â”€â”€ Tab: Create Post â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_create:
    st.header("ğŸš€ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ÑÑ‚")

    ideas = load_json(IDEAS_FILE, [])
    unused = [item["idea"] for item in ideas if not item.get("used", False)]

    input_mode = st.radio("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ¸Ğ´ĞµĞ¸", ["Ğ˜Ğ· ÑĞ¿Ğ¸ÑĞºĞ°", "Ğ’Ğ²ĞµÑÑ‚Ğ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ"], horizontal=True)

    if input_mode == "Ğ˜Ğ· ÑĞ¿Ğ¸ÑĞºĞ°":
        if unused:
            idea = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¸Ğ´ĞµÑ", unused)
        else:
            st.warning("ĞĞµÑ‚ Ğ½ĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ´ĞµĞ¹. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ Â«Ğ˜Ğ´ĞµĞ¸Â».")
            idea = ""
    else:
        idea = st.text_input("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¸Ğ´ĞµÑ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ğ°")

    # Generate
    if st.button("ğŸ¨ Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ÑÑ‚", disabled=not idea, use_container_width=True):
        prompts = load_prompts()
        env = load_env_values()

        with st.spinner("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ñ‚ĞµĞºÑÑ‚..."):
            try:
                post_text, image_prompt = generate_post(
                    idea,
                    provider=env.get("TEXT_PROVIDER", "claude"),
                    system_prompt=prompts["system_prompt"],
                    image_prompt_template=prompts["image_prompt_template"],
                )
                st.session_state["post_text"] = post_text
                st.session_state["image_prompt"] = image_prompt
                st.session_state["idea"] = idea
            except Exception as e:
                st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°: {e}")

        if "image_prompt" in st.session_state:
            with st.spinner("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ..."):
                try:
                    image_path = generate_image(
                        st.session_state["image_prompt"],
                        provider=env.get("IMAGE_PROVIDER", "gemini"),
                    )
                    st.session_state["image_path"] = image_path
                except Exception as e:
                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸: {e}")

            # Apply face swap if enabled (read from sidebar widget, not .env)
            if face_swap_prov and "image_path" in st.session_state:
                expert_b64_for_swap = get_expert_face_b64()
                if expert_b64_for_swap:
                    with st.spinner(f"ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ face swap ({face_swap_prov})..."):
                        try:
                            new_path = apply_face_swap(
                                st.session_state["image_path"],
                                expert_face_b64=expert_b64_for_swap,
                                method=face_swap_prov,
                                image_prompt=st.session_state.get("image_prompt", ""),
                            )
                            if new_path != st.session_state["image_path"]:
                                old = st.session_state["image_path"]
                                st.session_state["image_path"] = new_path
                                try:
                                    os.remove(old)
                                except OSError:
                                    pass
                                st.success("Face swap Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½!")
                        except Exception as e:
                            st.warning(f"Face swap Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ».")
                else:
                    st.info("Face swap Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ (Ñ„Ğ¾Ñ‚Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾)")

    # Preview
    if "post_text" in st.session_state:
        st.divider()
        st.subheader("ĞŸÑ€ĞµĞ²ÑŒÑ Ğ¿Ğ¾ÑÑ‚Ğ°")

        col_text, col_img = st.columns([3, 2])

        with col_text:
            edited_text = st.text_area(
                "Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ° (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ)",
                value=st.session_state["post_text"],
                height=300,
            )
            st.session_state["post_text"] = edited_text

            st.caption("ĞŸÑ€ĞµĞ´Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ HTML:")
            st.markdown(edited_text.replace("<b>", "**").replace("</b>", "**")
                        .replace("<i>", "*").replace("</i>", "*"), unsafe_allow_html=True)

        with col_img:
            if "image_path" in st.session_state and os.path.exists(st.session_state["image_path"]):
                st.image(st.session_state["image_path"], caption="Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ°", use_container_width=True)

            # Upload custom image
            custom_img = st.file_uploader(
                "ğŸ“· Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ",
                type=["jpg", "jpeg", "png"],
                key="create_custom_img",
            )
            if custom_img is not None:
                img = Image.open(custom_img)
                fd, custom_path = tempfile.mkstemp(suffix=".png", prefix="autoposter_custom_")
                os.close(fd)
                img.save(custom_path, "PNG")
                old_path = st.session_state.get("image_path")
                if old_path and os.path.exists(old_path):
                    try:
                        os.remove(old_path)
                    except OSError:
                        pass
                st.session_state["image_path"] = custom_path
                st.success("ĞšĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ·Ğ°Ğ¼ĞµĞ½ĞµĞ½Ğ°!")
                st.rerun()

            edited_img_prompt = st.text_area(
                "ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ)",
                value=st.session_state.get("image_prompt", ""),
                height=100,
            )
            st.session_state["image_prompt"] = edited_img_prompt

            if st.button("ğŸ”„ ĞŸĞµÑ€ĞµĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ"):
                env = load_env_values()
                with st.spinner("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ğ½Ğ¾Ğ²ÑƒÑ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ..."):
                    try:
                        old_path = st.session_state.get("image_path")
                        if old_path and os.path.exists(old_path):
                            os.remove(old_path)
                        image_path = generate_image(
                            st.session_state["image_prompt"],
                            provider=env.get("IMAGE_PROVIDER", "gemini"),
                        )
                        # Apply face swap if enabled (read from sidebar widget)
                        if face_swap_prov:
                            expert_b64_regen = get_expert_face_b64()
                            if expert_b64_regen:
                                try:
                                    new_path = apply_face_swap(
                                        image_path,
                                        expert_face_b64=expert_b64_regen,
                                        method=face_swap_prov,
                                        image_prompt=st.session_state.get("image_prompt", ""),
                                    )
                                    if new_path != image_path:
                                        os.remove(image_path)
                                        image_path = new_path
                                except Exception:
                                    pass
                        st.session_state["image_path"] = image_path
                        st.rerun()
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")

        # Publish
        st.divider()
        col_pub, col_regen = st.columns(2)

        with col_pub:
            if st.button("ğŸ“¤ ĞĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Telegram", use_container_width=True, type="primary"):
                env = load_env_values()
                if not env.get("TELEGRAM_BOT_TOKEN") or not env.get("TELEGRAM_CHANNEL_ID"):
                    st.error("Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Telegram Bot Token Ğ¸ Channel ID Ğ² Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ñ…!")
                elif "image_path" not in st.session_state:
                    st.error("Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ!")
                else:
                    with st.spinner("ĞŸÑƒĞ±Ğ»Ğ¸ĞºÑƒÑ..."):
                        try:
                            result = send_post(
                                st.session_state["image_path"],
                                st.session_state["post_text"],
                                bot_token=env.get("TELEGRAM_BOT_TOKEN"),
                                channel_id=env.get("TELEGRAM_CHANNEL_ID"),
                            )
                            msg_id = result["result"]["message_id"]

                            # Mark idea as used
                            current_idea = st.session_state.get("idea", "")
                            ideas = load_json(IDEAS_FILE, [])
                            for item in ideas:
                                if item["idea"] == current_idea and not item.get("used"):
                                    item["used"] = True
                                    break
                            save_json(IDEAS_FILE, ideas)

                            # Save history
                            history = load_json(HISTORY_FILE, [])
                            history.append({
                                "date": datetime.now().isoformat(),
                                "idea": current_idea,
                                "post_text": st.session_state["post_text"],
                                "text_provider": env.get("TEXT_PROVIDER", ""),
                                "image_provider": env.get("IMAGE_PROVIDER", ""),
                                "message_id": msg_id,
                            })
                            save_json(HISTORY_FILE, history)

                            # Cleanup
                            old_path = st.session_state.pop("image_path", None)
                            if old_path and os.path.exists(old_path):
                                os.remove(old_path)
                            st.session_state.pop("post_text", None)
                            st.session_state.pop("image_prompt", None)
                            st.session_state.pop("idea", None)

                            st.session_state["_flash_success"] = True
                            st.session_state["_flash_msg"] = f"âœ… ĞĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ¾! message_id: {msg_id}"
                            st.rerun()

                        except Exception as e:
                            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸: {e}")

        with col_regen:
            if st.button("ğŸ”„ ĞŸĞµÑ€ĞµĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²ÑÑ‘", use_container_width=True):
                old_path = st.session_state.pop("image_path", None)
                if old_path and os.path.exists(old_path):
                    os.remove(old_path)
                st.session_state.pop("post_text", None)
                st.session_state.pop("image_prompt", None)
                st.rerun()

# â”€â”€ Tab: Ideas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_ideas:
    st.header("ğŸ“‹ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ´ĞµÑĞ¼Ğ¸")

    ideas = load_json(IDEAS_FILE, [])

    # Add new idea
    st.subheader("Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¸Ğ´ĞµÑ")
    new_idea = st.text_input("ĞĞ¾Ğ²Ğ°Ñ Ğ¸Ğ´ĞµÑ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ğ°", key="new_idea_input")
    if st.button("â• Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ", disabled=not new_idea):
        ideas.append({"idea": new_idea, "used": False})
        save_json(IDEAS_FILE, ideas)
        st.success(f"Ğ˜Ğ´ĞµÑ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ°: {new_idea}")
        st.rerun()

    st.divider()

    # Ideas table
    if not ideas:
        st.info("ĞŸĞ¾ĞºĞ° Ğ½ĞµÑ‚ Ğ¸Ğ´ĞµĞ¹. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¿ĞµÑ€Ğ²ÑƒÑ!")
    else:
        for i, item in enumerate(ideas):
            col_status, col_text, col_actions = st.columns([1, 6, 3])

            with col_status:
                if item.get("used"):
                    st.markdown("âœ…")
                else:
                    st.markdown("â³")

            with col_text:
                if item.get("used"):
                    st.markdown(f"~~{item['idea']}~~")
                else:
                    st.write(item["idea"])

            with col_actions:
                btn_col1, btn_col2 = st.columns(2)
                with btn_col1:
                    if item.get("used") and st.button("ğŸ”„", key=f"reset_{i}", help="Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ"):
                        ideas[i]["used"] = False
                        save_json(IDEAS_FILE, ideas)
                        st.rerun()
                with btn_col2:
                    if st.button("ğŸ—‘ï¸", key=f"del_{i}", help="Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ"):
                        ideas.pop(i)
                        save_json(IDEAS_FILE, ideas)
                        st.rerun()

    st.divider()
    st.caption(f"Ğ’ÑĞµĞ³Ğ¾ Ğ¸Ğ´ĞµĞ¹: {len(ideas)} | ĞĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ…: {sum(1 for i in ideas if not i.get('used'))}")

# â”€â”€ Tab: History â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_history:
    st.header("ğŸ“Š Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¹")

    history = load_json(HISTORY_FILE, [])

    if not history:
        st.info("ĞŸĞ¾ĞºĞ° Ğ½ĞµÑ‚ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ².")
    else:
        for entry in reversed(history):
            with st.expander(f"ğŸ“… {entry['date'][:16]} â€” {entry.get('idea', 'N/A')}", expanded=False):
                st.markdown(
                    f"**Ğ˜Ğ´ĞµÑ:** {entry.get('idea', 'N/A')}  \n"
                    f"**Ğ”Ğ°Ñ‚Ğ°:** {entry.get('date', 'N/A')}  \n"
                    f"**ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹:** Ñ‚ĞµĞºÑÑ‚ â€” `{entry.get('text_provider', 'N/A')}`, "
                    f"ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° â€” `{entry.get('image_provider', 'N/A')}`  \n"
                    f"**Message ID:** `{entry.get('message_id', 'N/A')}`"
                )

                if entry.get("post_text"):
                    post = entry["post_text"]
                    st.divider()
                    st.caption(f"Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ° ({len(post)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²):")
                    st.text_area(
                        "Ğ¢ĞµĞºÑÑ‚ (Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ HTML)",
                        value=post,
                        height=250,
                        disabled=True,
                        key=f"hist_{entry.get('message_id', id(entry))}",
                    )
                    st.caption("ĞŸÑ€ĞµĞ´Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€:")
                    st.markdown(
                        post.replace("<b>", "**").replace("</b>", "**")
                        .replace("<i>", "*").replace("</i>", "*"),
                        unsafe_allow_html=True,
                    )

        st.caption(f"Ğ’ÑĞµĞ³Ğ¾ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¹: {len(history)}")

# â”€â”€ Tab: Auto-publish â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_auto:
    st.header("â° ĞĞ²Ñ‚Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ")

    # â”€â”€ Toggle: enable / disable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    github_cfg = read_provider_cfg_from_github()
    current_enabled = github_cfg.get("AUTOPUBLISH_ENABLED", "true").lower() != "false"

    st.subheader("ğŸ”˜ Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ")

    new_enabled = st.toggle(
        "Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°",
        value=current_enabled,
        key="autopublish_toggle",
    )

    # Detect toggle change
    if new_enabled != current_enabled:
        with st.spinner("ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑÑ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ Ğ½Ğ° GitHub..."):
            ok, err = update_github_provider_cfg(
                github_cfg.get("TEXT_PROVIDER", "openai"),
                github_cfg.get("IMAGE_PROVIDER", "openai"),
                autopublish_enabled=new_enabled,
            )
            if ok:
                st.success("âœ… ĞĞ²Ñ‚Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ " + ("Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°" if new_enabled else "Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ°"))
                st.rerun()
            else:
                st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ: {err}")

    if new_enabled:
        st.info(
            "ğŸ“… **Ğ Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ:**\n"
            "- **05:00 ĞœĞ¡Ğš** â€” Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ° (Ñ‚ĞµĞºÑÑ‚ + ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ°)\n"
            "- **05:00â€“15:00** â€” Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ, Ğ¾Ñ‚Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ\n"
            "- **15:00 ĞœĞ¡Ğš** â€” ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ¾ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ, Ğ¿Ğ¾ÑÑ‚ ÑƒĞ¹Ğ´Ñ‘Ñ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸"
        )
    else:
        st.warning("â¸ï¸ ĞĞ²Ñ‚Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ°. ĞŸĞ¾ÑÑ‚Ñ‹ Ğ½Ğµ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸.")

    st.divider()

    # â”€â”€ Pending draft panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    st.subheader("ğŸ“‹ Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº Ğ¿Ğ¾ÑÑ‚Ğ°")

    # Fetch pending_post.json from GitHub
    pending_raw, pending_sha = read_github_file(PENDING_POST_PATH)

    if pending_raw is None:
        st.info("ğŸ“­ ĞĞµÑ‚ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ°. Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº Ğ±ÑƒĞ´ĞµÑ‚ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ² **05:00 ĞœĞ¡Ğš**.")
    else:
        try:
            pending = json.loads(pending_raw)
        except json.JSONDecodeError:
            st.error("ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ pending_post.json")
            pending = None

        if pending:
            status = pending.get("status", "unknown")
            created = pending.get("created_at", "")[:16]

            if status == "published":
                # â”€â”€ Already published â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                published_by = pending.get("published_by", "?")
                published_at = (pending.get("published_at") or "")[:16]
                msg_id = pending.get("message_id", "?")
                by_label = "Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ" if published_by == "manual" else "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸"

                st.success(
                    f"âœ… ĞŸĞ¾ÑÑ‚ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½ **{by_label}** "
                    f"Ğ² {published_at} (message_id: {msg_id})"
                )

                with st.expander("ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ÑÑ‚", expanded=False):
                    st.markdown(
                        pending.get("post_text", "").replace("<b>", "**").replace("</b>", "**")
                        .replace("<i>", "*").replace("</i>", "*"),
                        unsafe_allow_html=True,
                    )
                    if pending.get("image_base64"):
                        st.image(
                            base64_to_bytes(pending["image_base64"]),
                            caption="ĞšĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ¿Ğ¾ÑÑ‚Ğ°",
                            use_container_width=True,
                        )

            elif status == "pending":
                # â”€â”€ Pending draft â€” editable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.warning(f"â³ Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº Ğ¾Ñ‚ **{created}** Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµÑ‚ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸")
                st.caption(f"Ğ˜Ğ´ĞµÑ: **{pending.get('idea', 'N/A')}** | "
                           f"ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹: Ñ‚ĞµĞºÑÑ‚ â€” `{pending.get('text_provider')}`, "
                           f"ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° â€” `{pending.get('image_provider')}`")

                col_text, col_img = st.columns([3, 2])

                with col_text:
                    draft_text = st.text_area(
                        "Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ° (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹)",
                        value=pending.get("post_text", ""),
                        height=300,
                        key="draft_text_editor",
                    )

                    st.caption("ĞŸÑ€ĞµĞ´Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ HTML:")
                    st.markdown(
                        draft_text.replace("<b>", "**").replace("</b>", "**")
                        .replace("<i>", "*").replace("</i>", "*"),
                        unsafe_allow_html=True,
                    )

                with col_img:
                    if pending.get("image_base64"):
                        st.image(
                            base64_to_bytes(pending["image_base64"]),
                            caption="Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ°",
                            use_container_width=True,
                        )

                    # Upload custom image for draft
                    draft_custom_img = st.file_uploader(
                        "ğŸ“· Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ",
                        type=["jpg", "jpeg", "png"],
                        key="draft_custom_img",
                    )
                    if draft_custom_img is not None:
                        img = Image.open(draft_custom_img)
                        buf = io.BytesIO()
                        img.convert("RGB").save(buf, format="JPEG", quality=85)
                        new_b64 = base64.b64encode(buf.getvalue()).decode("ascii")

                        pending["image_base64"] = new_b64
                        ok, err = write_github_file(
                            PENDING_POST_PATH,
                            json.dumps(pending, ensure_ascii=False, indent=2),
                            pending_sha,
                            "Update draft: custom image uploaded [manual]",
                        )
                        if ok:
                            st.success("ĞšĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ·Ğ°Ğ¼ĞµĞ½ĞµĞ½Ğ°!")
                            st.rerun()
                        else:
                            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {err}")

                    draft_img_prompt = st.text_area(
                        "ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸",
                        value=pending.get("image_prompt", ""),
                        height=100,
                        key="draft_img_prompt_editor",
                    )

                    if st.button("ğŸ”„ ĞŸĞµÑ€ĞµĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ", key="draft_regen_img"):
                        env = load_env_values()
                        with st.spinner("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ğ½Ğ¾Ğ²ÑƒÑ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ..."):
                            try:
                                new_image_path = generate_image(
                                    draft_img_prompt,
                                    provider=env.get("IMAGE_PROVIDER", "openai"),
                                )
                                # Apply face swap if enabled
                                if face_swap_prov:
                                    expert_b64_regen = get_expert_face_b64()
                                    if expert_b64_regen:
                                        try:
                                            swapped = apply_face_swap(
                                                new_image_path,
                                                expert_face_b64=expert_b64_regen,
                                                method=face_swap_prov,
                                                image_prompt=draft_img_prompt,
                                            )
                                            if swapped != new_image_path:
                                                os.remove(new_image_path)
                                                new_image_path = swapped
                                        except Exception as e:
                                            st.warning(f"Face swap Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
                                new_b64 = image_to_base64(new_image_path)
                                os.remove(new_image_path)

                                # Update pending on GitHub
                                pending["image_base64"] = new_b64
                                pending["image_prompt"] = draft_img_prompt
                                ok, err = write_github_file(
                                    PENDING_POST_PATH,
                                    json.dumps(pending, ensure_ascii=False, indent=2),
                                    pending_sha,
                                    "Update draft: regenerated image [manual]",
                                )
                                if ok:
                                    st.success("ĞšĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ°!")
                                    st.rerun()
                                else:
                                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ½Ğ° GitHub: {err}")
                            except Exception as e:
                                st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")

                # â”€â”€ Action buttons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.divider()
                col_pub, col_save = st.columns(2)

                with col_pub:
                    if st.button("ğŸ“¤ ĞĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Telegram", key="draft_publish",
                                 use_container_width=True, type="primary"):
                        env = load_env_values()
                        bot_token = env.get("TELEGRAM_BOT_TOKEN") or os.getenv("TELEGRAM_BOT_TOKEN", "")
                        channel_id = env.get("TELEGRAM_CHANNEL_ID") or os.getenv("TELEGRAM_CHANNEL_ID", "")

                        if not bot_token or not channel_id:
                            st.error("Ğ—Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Telegram Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸!")
                        elif not pending.get("image_base64"):
                            st.error("ĞĞµÑ‚ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸ Ğ² Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞµ!")
                        else:
                            with st.spinner("ĞŸÑƒĞ±Ğ»Ğ¸ĞºÑƒÑ..."):
                                try:
                                    # Decode image to temp file
                                    tmp_path = base64_to_tempfile(pending["image_base64"])
                                    try:
                                        result = send_post(
                                            tmp_path,
                                            draft_text,
                                            bot_token=bot_token,
                                            channel_id=channel_id,
                                        )
                                        msg_id = result["result"]["message_id"]
                                    finally:
                                        try:
                                            os.remove(tmp_path)
                                        except OSError:
                                            pass

                                    # 1. Update pending_post.json on GitHub
                                    pending["status"] = "published"
                                    pending["published_at"] = datetime.now().isoformat()
                                    pending["message_id"] = msg_id
                                    pending["published_by"] = "manual"
                                    pending["post_text"] = draft_text
                                    ok1, err1 = write_github_file(
                                        PENDING_POST_PATH,
                                        json.dumps(pending, ensure_ascii=False, indent=2),
                                        pending_sha,
                                        f"Manual publish: message_id={msg_id} [manual]",
                                    )

                                    # 2. Update ideas.json on GitHub
                                    ideas_raw, ideas_sha = read_github_file("ideas.json")
                                    if ideas_raw:
                                        ideas_data = json.loads(ideas_raw)
                                        idx = pending.get("idea_index")
                                        if idx is not None and idx < len(ideas_data):
                                            ideas_data[idx]["used"] = True
                                            write_github_file(
                                                "ideas.json",
                                                json.dumps(ideas_data, ensure_ascii=False, indent=2),
                                                ideas_sha,
                                                f"Mark idea #{idx} as used [manual]",
                                            )

                                    # 3. Update history.json on GitHub
                                    hist_raw, hist_sha = read_github_file("history.json")
                                    hist_data = json.loads(hist_raw) if hist_raw else []
                                    hist_data.append({
                                        "date": datetime.now().isoformat(),
                                        "idea": pending.get("idea", ""),
                                        "post_text": draft_text,
                                        "text_provider": pending.get("text_provider", ""),
                                        "image_provider": pending.get("image_provider", ""),
                                        "message_id": msg_id,
                                    })
                                    write_github_file(
                                        "history.json",
                                        json.dumps(hist_data, ensure_ascii=False, indent=2),
                                        hist_sha,
                                        f"Add history entry for msg {msg_id} [manual]",
                                    )

                                    # Also update local files
                                    local_ideas = load_json(IDEAS_FILE, [])
                                    idx = pending.get("idea_index")
                                    if idx is not None and idx < len(local_ideas):
                                        local_ideas[idx]["used"] = True
                                        save_json(IDEAS_FILE, local_ideas)

                                    local_hist = load_json(HISTORY_FILE, [])
                                    local_hist.append({
                                        "date": datetime.now().isoformat(),
                                        "idea": pending.get("idea", ""),
                                        "post_text": draft_text,
                                        "text_provider": pending.get("text_provider", ""),
                                        "image_provider": pending.get("image_provider", ""),
                                        "message_id": msg_id,
                                    })
                                    save_json(HISTORY_FILE, local_hist)

                                    st.session_state["_flash_success"] = True
                                    st.session_state["_flash_msg"] = f"âœ… ĞĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ¾! message_id: {msg_id}"
                                    st.rerun()

                                except Exception as e:
                                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸: {e}")

                with col_save:
                    if st.button("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°", key="draft_save_text",
                                 use_container_width=True):
                        pending["post_text"] = draft_text
                        pending["image_prompt"] = draft_img_prompt
                        ok, err = write_github_file(
                            PENDING_POST_PATH,
                            json.dumps(pending, ensure_ascii=False, indent=2),
                            pending_sha,
                            "Update draft text [manual]",
                        )
                        if ok:
                            st.success("Ğ¢ĞµĞºÑÑ‚ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ğ½Ğ° GitHub!")
                            st.rerun()
                        else:
                            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {err}")

            else:
                st.info(f"Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ°: `{status}`")

    # â”€â”€ Manual generate (for testing) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    st.divider()
    st.subheader("ğŸ§ª Ğ ÑƒÑ‡Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸ĞºĞ°")
    st.caption("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº Ğ¿Ñ€ÑĞ¼Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ (Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)")

    ideas = load_json(IDEAS_FILE, [])
    next_idea = None
    next_idx = None
    for i, item in enumerate(ideas):
        if not item.get("used"):
            next_idea = item["idea"]
            next_idx = i
            break

    if next_idea:
        st.info(f"Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ°Ñ Ğ¸Ğ´ĞµÑ: **{next_idea}**")

        if st.button("ğŸ¨ Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº", key="manual_gen", use_container_width=True):
            env = load_env_values()
            prompts = load_prompts()

            with st.spinner("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ Ñ‚ĞµĞºÑÑ‚..."):
                try:
                    post_text, image_prompt = generate_post(
                        next_idea,
                        provider=env.get("TEXT_PROVIDER", "openai"),
                        system_prompt=prompts["system_prompt"],
                        image_prompt_template=prompts["image_prompt_template"],
                    )
                except Exception as e:
                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°: {e}")
                    post_text = None

            if post_text:
                with st.spinner("Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ..."):
                    try:
                        img_path = generate_image(
                            image_prompt,
                            provider=env.get("IMAGE_PROVIDER", "openai"),
                        )
                        # Apply face swap if enabled (read from sidebar widget)
                        if face_swap_prov:
                            expert_b64_draft = get_expert_face_b64()
                            if expert_b64_draft:
                                try:
                                    new_path = apply_face_swap(
                                        img_path,
                                        expert_face_b64=expert_b64_draft,
                                        method=face_swap_prov,
                                        image_prompt=image_prompt,
                                    )
                                    if new_path != img_path:
                                        os.remove(img_path)
                                        img_path = new_path
                                except Exception as e:
                                    st.warning(f"Face swap Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
                        img_b64 = image_to_base64(img_path)
                        os.remove(img_path)
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸: {e}")
                        img_b64 = None

                if img_b64:
                    # Save to GitHub as pending draft
                    draft_data = {
                        "status": "pending",
                        "created_at": datetime.now().isoformat(),
                        "idea": next_idea,
                        "idea_index": next_idx,
                        "post_text": post_text,
                        "image_prompt": image_prompt,
                        "image_base64": img_b64,
                        "text_provider": env.get("TEXT_PROVIDER", "openai"),
                        "image_provider": env.get("IMAGE_PROVIDER", "openai"),
                        "face_swap_provider": face_swap_prov if face_swap_prov else "",
                        "published_at": None,
                        "message_id": None,
                        "published_by": None,
                    }

                    # Read existing SHA if file exists
                    _, existing_sha = read_github_file(PENDING_POST_PATH)

                    with st.spinner("Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ñ‡ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº Ğ½Ğ° GitHub..."):
                        ok, err = write_github_file(
                            PENDING_POST_PATH,
                            json.dumps(draft_data, ensure_ascii=False, indent=2),
                            existing_sha,
                            "Manual draft generation [streamlit]",
                        )
                        if ok:
                            st.session_state["_flash_success"] = True
                            st.session_state["_flash_msg"] = "âœ… Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ¸Ğº ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½!"
                            st.rerun()
                        else:
                            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ½Ğ° GitHub: {err}")
    else:
        st.warning("ĞĞµÑ‚ Ğ½ĞµĞ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ´ĞµĞ¹. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞµ Â«Ğ˜Ğ´ĞµĞ¸Â».")
